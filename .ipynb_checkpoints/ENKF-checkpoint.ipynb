{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import lorenz63_fdm\n",
    "from nmc import nmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = np.array([[8, 0, 30]]).T\n",
    "end_time = 10\n",
    "dt = 0.01\n",
    "ts = np.arange(0, end_time, dt)\n",
    "\n",
    "nature = lorenz63_fdm(x0, ts)\n",
    "nature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2841561 ,  2.15577354, -0.57402692],\n",
       "       [ 2.15577354,  2.7865047 , -0.16715354],\n",
       "       [-0.57402692, -0.16715354,  6.00974005]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pb = nmc(lorenz63_fdm, nature, dt, 1, 0.04)\n",
    "Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_intv = 8\n",
    "obs = nature + np.sqrt(2) * np.random.randn(*nature.shape)\n",
    "obs = obs[:,::obs_intv]\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.eye(3) * 2\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18],\n",
       "       [-10],\n",
       "       [ 45]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a very bad initial condition\n",
    "X_ini = x0 + np.array([[10, -10, 15]]).T\n",
    "X_ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_ens = 30\n",
    "X_ens_ini = np.random.multivariate_normal(X_ini.ravel(), Pb, size=N_ens).T  # (ndim, N_ens)\n",
    "X_ens_ini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_rmse(nature, analysis, obs_intv):\n",
    "    return np.sqrt(np.mean((analysis[:,::obs_intv] - nature[:,::obs_intv]) ** 2, axis=0))\n",
    "\n",
    "def plot_assimilation_result(nature, obs, analysis, obs_intv):\n",
    "    fig, axs = plt.subplots(nrows=4, figsize=(8, 8), sharex=True)\n",
    "    for i in range(3):\n",
    "        axs[i].plot(ts, nature[i,:], color='#024BC7', label='nature')\n",
    "        axs[i].plot(ts[::obs_intv], obs[i,:], '.', color='#024BC7', label='obs')\n",
    "        axs[i].plot(ts, analysis[i,:], color='#FFA500', label='analysis')\n",
    "    axs[0].legend()\n",
    "    axs[0].set_title('X')\n",
    "    axs[1].set_title('Y')\n",
    "    axs[2].set_title('Z')\n",
    "    \n",
    "    rmse = da_rmse(nature, analysis, obs_intv)\n",
    "    axs[3].plot(ts[::obs_intv], rmse, '.-')\n",
    "    axs[3].set_title('RMSE')\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagWarning(UserWarning):\n",
    "    \"\"\"Used in serially assimilation when R is not diagonal\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DAbase:\n",
    "    def __init__(self, model, dt, store_history=False):\n",
    "        self._isstore = store_history\n",
    "        self._params = {'alpha': 0, 'inflat': 1}\n",
    "        self.model = model\n",
    "        self.dt = dt\n",
    "        self.X_ini = None\n",
    "        \n",
    "    def set_params(self, param_list, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if key in param_list:\n",
    "                self._params[key] = kwargs.get(key)\n",
    "            else:\n",
    "                raise ValueError(f'Invalid parameter: {key}')\n",
    "        \n",
    "    def _check_params(self, param_list):\n",
    "        missing_params = []\n",
    "        for var in param_list:\n",
    "            if self._params.get(var) is None:\n",
    "                missing_params.append(var)\n",
    "        return missing_params\n",
    "    \n",
    "    \n",
    "class EnsembleBase(DAbase):    \n",
    "    def __init__(self, model, dt, store_history=False):\n",
    "        super().__init__(model, dt, store_history)\n",
    "        self._param_list = [\n",
    "            'X_ens_ini', \n",
    "            'obs', \n",
    "            'obs_interv', \n",
    "            'R', \n",
    "            'H_func', \n",
    "            'alpha', \n",
    "            'inflat',\n",
    "            'local',\n",
    "        ]\n",
    "    \n",
    "    def list_params(self):\n",
    "        return self._param_list\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        local = kwargs.get('local')\n",
    "        if local is not None and not isinstance(local, (tuple, list)):\n",
    "            kwargs['local'] = tuple(local)\n",
    "        super().set_params(self._param_list, **kwargs)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        if self._params.get('H_func') is None:\n",
    "            H_func = lambda arr: arr\n",
    "            self._params['H_func']\n",
    "        \n",
    "        missing_params = super()._check_params(self._param_list)\n",
    "        if missing_params:\n",
    "            raise ValueError(f\"Missing parameters: {missing_params}\")\n",
    "            \n",
    "    def _analysis(self):\n",
    "        pass\n",
    "            \n",
    "    def cycle(self, **kwargs):\n",
    "        self._check_params()\n",
    "        \n",
    "        model = self.model\n",
    "        dt = self.dt\n",
    "        cycle_len = self._params['obs_interv']\n",
    "        cycle_num = self._params['obs'].shape[1]\n",
    "        \n",
    "        xb = self._params['X_ens_ini'].copy()\n",
    "        obs = self._params['obs']\n",
    "        R = self._params['R']\n",
    "        H_func = self._params['H_func']\n",
    "        alpha = self._params['alpha']\n",
    "        inflat = self._params['inflat']\n",
    "        local = self._params['local']\n",
    "        \n",
    "        ndim, N_ens = xb.shape\n",
    "        background = np.zeros((N_ens, ndim, cycle_len*cycle_num))\n",
    "        analysis = np.zeros_like(background)\n",
    "        \n",
    "        t_start = 0\n",
    "        ts = np.linspace(t_start, (cycle_len-1)*dt, cycle_len)\n",
    "        \n",
    "        for nc in range(cycle_num):\n",
    "            # analysis\n",
    "            xa = self._analysis(xb, obs[:,[nc]], R, H_func, *local, **kwargs)\n",
    "            \n",
    "            # inflat\n",
    "            xa_perturb = xa - xa.mean(axis=1)[:,np.newaxis]\n",
    "            xa_perturb *= inflat\n",
    "            xa = xa.mean(axis=1)[:,np.newaxis] + xa_perturb\n",
    "            \n",
    "            # ensemble forecast\n",
    "            for iens in range(N_ens):\n",
    "                x_forecast = model(xa[:,iens], ts)   # (ndim, ts.size)\n",
    "                \n",
    "                idx1 = nc*cycle_len\n",
    "                idx2 = (nc+1)*cycle_len\n",
    "                analysis[iens,:,idx1:idx2] = x_forecast\n",
    "                background[iens,:,[idx1]] = xb[:,iens]\n",
    "                background[iens,:,(idx1+1):idx2] = x_forecast[:,1:]\n",
    "                \n",
    "                # xb for next cycle\n",
    "                xb[:,iens] = x_forecast[:,-1]\n",
    "                \n",
    "            # for next cycle\n",
    "            t_start = int(ts[-1] + dt)\n",
    "            ts = np.linspace(t_start, t_start+(cycle_len-1)*dt, cycle_len)\n",
    "            \n",
    "        self.background = background\n",
    "        self.analysis = analysis\n",
    "\n",
    "\n",
    "class EnKF(EnsembleBase):\n",
    "    def _check_params(self):          \n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            loc_oo = np.ones((ndim_obs, ndim_obs))\n",
    "            self._params['local'] = (loc_mo, loc_oo)            \n",
    "        super()._check_params()\n",
    " \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo, loc_oo):\n",
    "        \"\"\"xb.shape = (n_dim, n_ens)\"\"\"\n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        Xb_perturb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        HXb_perturb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        \n",
    "        PfH_T = Xb_perturb @ HXb_perturb.T / (N_ens-1)\n",
    "        HPfH_T = HXb_perturb @ HXb_perturb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(loc_oo * HPfH_T + R)\n",
    "        \n",
    "        yo_ens = np.random.multivariate_normal(yo.ravel(), R, size=N_ens).T   # (ndim_yo, N_ens)\n",
    "        xa_ens = np.zeros((xb.shape[0], N_ens))\n",
    "        for iens in range(N_ens):            \n",
    "            xa_ens[:,[iens]] = xb[:,[iens]] + K @ (yo_ens[:,[iens]] - H_func(xb[:,[iens]]))\n",
    "            \n",
    "        return xa_ens\n",
    "\n",
    "\n",
    "class EnSRF(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EnSRF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "        \n",
    "    def _analysis(self, xb, yo, R, H_func=None, loc_mo=None):\n",
    "        \"\"\"xb.shape = (n_dim, n_ens)\"\"\"\n",
    "        if H_func is None:\n",
    "            H_func = lambda arr: arr\n",
    "        \n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        xb_pertb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        \n",
    "        # update `xb_mean`\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        Hxb_pertb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        PfH_T = xb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        HPfH_T = Hxb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(HPfH_T + R)\n",
    "        xa_mean = xb_mean + K @ (yo - H_func(xb_mean))\n",
    "        \n",
    "        # update `xb_pertb`\n",
    "        xa_pertb = xb_pertb.copy()\n",
    "        for j_ens in range(N_ens):\n",
    "            # assimilate one observation at a time\n",
    "            for io, y in enumerate(yo):\n",
    "                iR = R[io,io]\n",
    "                iHxb_pertb = Hxb_pertb[[io],:]   # (1, N_ens)\n",
    "                \n",
    "                PfH_T = xb_pertb @ iHxb_pertb.T / (N_ens-1)\n",
    "                HPfH_T = iHxb_pertb @ iHxb_pertb.T / (N_ens-1)\n",
    "                gamma = 1 / (1 + np.sqrt(iR / (HPfH_T+iR)))\n",
    "                K = loc_mo[:,[io]] * PfH_T / (HPfH_T + iR)\n",
    "                \n",
    "                xa_pertb_j = xa_pertb[:,[j_ens]]\n",
    "                xa_pertb[:,[j_ens]] = xa_pertb_j - gamma * K * iHxb_pertb[0,j_ens]\n",
    "                \n",
    "        xa_ens = xa_mean + xa_pertb\n",
    "        return xa_ens\n",
    "        \n",
    "\n",
    "class ETKF(EnsembleBase):\n",
    "    \"\"\"\n",
    "    Ensemble Transform Kalman Filter\n",
    "    \n",
    "    It should note that localization is only used for updating ensemble mean \n",
    "    of K method (e.g etkf.cycle(mean_method='K')). There is no localization\n",
    "    for w method (e.g etkf.cycle(mean_method='w')).\n",
    "    \n",
    "    And localization is for ensemble mean only, there is no localization for \n",
    "    updating ensemble perturbation.\n",
    "    \n",
    "    *Reference\n",
    "    Update ensemble mean of w method:\n",
    "        Harlim and Hunt: Local Ensemble Transform Kalman Filter: An efficient\n",
    "        scheme for assimilating atmospheric data.\n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "    Update ensemble perturbation:\n",
    "        Tippett, M. K., J. L. Anderson, C. H. Bishop, T. M. Hamill, and J. S. \n",
    "        Whitaker, 2003: Ensemble square root filters.\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2      \n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            loc_oo = np.ones((ndim_obs, ndim_obs))\n",
    "            self._params['local'] = (loc_mo, loc_oo)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "    \n",
    "    def _analysis_mean_w(self, xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R):\n",
    "        \"\"\"\n",
    "        Using the w vector in Harlim and Hunt* to update background ensemble\n",
    "        mean to analysis mean.\n",
    "        *Reference: \n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "        \"\"\"\n",
    "        P_tilt = np.linalg.inv(Hxb_pertb.T @ np.linalg.inv(R) @ Hxb_pertb + (N_ens-1) * np.eye(N_ens))\n",
    "        w = P_tilt @ Hxb_pertb.T @ np.linalg.inv(R) @ (yo - Hxb_mean)\n",
    "        xa_mean = xb_mean + xb_pertb @ w\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_mean_K(self, xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo):\n",
    "        \"\"\"\n",
    "        Using the K matrix (Kalman gain matrix) in traditional Kalman filter to\n",
    "        upate background ensemble mean to analysis ensemble mean.\n",
    "        \"\"\"\n",
    "        PfH_T = xb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        HPfH_T = Hxb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(loc_oo * HPfH_T + R)\n",
    "        xa_mean = xb_mean + K @ (yo - H_func(xb_mean))\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_perturb(self, xb_pertb, Hxb_pertb, N_ens, R):\n",
    "        \"\"\"\n",
    "        Update background ensemble perturbation tp analysis ensemble perturbation.\n",
    "        *Reference:\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2\n",
    "        \"\"\"\n",
    "        Z = xb_pertb / np.sqrt(N_ens-1)\n",
    "        HZ = Hxb_pertb / np.sqrt(N_ens-1)\n",
    "        eigval, C = np.linalg.eig(HZ.T @ np.linalg.inv(R) @ HZ)\n",
    "        S = np.diag(eigval)\n",
    "        T = C @ np.linalg.inv(sqrtm(S+np.eye(N_ens)))\n",
    "        T = T.real   # imag part is likely due to numerical error\n",
    "        xa_pertb = xb_pertb @ T\n",
    "        return xa_pertb\n",
    "        \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo, loc_oo, mean_method='w'):       \n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        xb_pertb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        Hxb_pertb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        \n",
    "        if mean_method == 'w':\n",
    "            xa_mean = self._analysis_mean_w(xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R)\n",
    "        elif mean_method == 'K':\n",
    "            xa_mean = self._analysis_mean_K(xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo)\n",
    "        else:\n",
    "            raise TypeError('`mean_method` should be \"w\" or \"K\"')\n",
    "            \n",
    "        xa_pertb = self._analysis_perturb(xb_pertb, Hxb_pertb, N_ens, R)\n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa\n",
    "    \n",
    "    def cycle(self, mean_method='w'):\n",
    "        super().cycle(mean_method=mean_method)\n",
    "        \n",
    "\n",
    "class EAKF(EnsembleBase): \n",
    "    \"\"\"\n",
    "    Ensemble Adjustment Kalman Filter\n",
    "    \n",
    "    It based on the 2-step procedure of Anderson (2003), and followed the \n",
    "    step-by-step introduction of Shen et al. (2018).\n",
    "    \n",
    "    *Reference\n",
    "    Zheqi Shen, Youmin Tang, Xiaojing Li, Yanqiu Gao, and Junde Li, 2018:\n",
    "    On the localization in strongly coupled ensemble data assimilationusing \n",
    "    a two-scale Lorenz model\n",
    "    https://www.nonlin-processes-geophys-discuss.net/npg-2018-50/\n",
    "    Anderson, 2003: A local least squares framework for ensemble filtering\n",
    "    https://doi.org/10.1175/1520-0493(2003)131<0634:ALLSFF>2.0.CO;2\n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "    \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):            \n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        # serially assimilation\n",
    "        xa = xb.copy()\n",
    "        for io, iyo in enumerate(yo):\n",
    "            ### step 1\n",
    "            # estimate background field at the observation space\n",
    "            yp = np.empty(N_ens)\n",
    "            for iens in range(N_ens):\n",
    "                yp[iens] = H_func(xa[:,[iens]])[io]\n",
    "                \n",
    "            # analysis for the background field at the observation space\n",
    "            yp_mean = yp.mean()\n",
    "            yp_var = yp.var()\n",
    "            r = R[io,io]\n",
    "            yu_var = 1 / (1/yp_var + 1/r)\n",
    "            yu_mean = yu_var * (yp_mean / yp_var + iyo / r)\n",
    "            yu = np.sqrt(yu_var / yp_var) * (yp - yp_mean) + yu_mean   # (N_ens,)\n",
    "            increment_y = yu - yp   # (N_ens,)\n",
    "            \n",
    "            ### step 2 \n",
    "            for jstate in range(N_x):\n",
    "                cov_xy = np.cov(xa[jstate,:], yp)[0,1]\n",
    "                increment_x = cov_xy / yp_var * increment_y\n",
    "                xa[jstate,:] = xa[jstate,:] + loc_mo[jstate,io] * increment_x\n",
    "                \n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.8579315684896274\n",
      "EnSRF, Mean RMSE:  0.9565964031879403\n",
      "ETKF, Mean RMSE:  0.8916293338355986\n",
      "EAKF, Mean RMSE:  0.8847446160796265\n"
     ]
    }
   ],
   "source": [
    "for Da in [EnKF, EnSRF, ETKF, EAKF]:\n",
    "    da = Da(lorenz63_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "    }\n",
    "    da.set_params(**params)\n",
    "    da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import lorenz96_fdm\n",
    "\n",
    "x0 = np.random.randint(low=0, high=9, size=40)\n",
    "x0 = x0[:,np.newaxis]  # (40, 1)\n",
    "end_time = 10\n",
    "dt = 0.01\n",
    "ts = np.arange(0, end_time, dt)\n",
    "nature = lorenz96_fdm(x0, ts)\n",
    "\n",
    "Pb = nmc(lorenz96_fdm, nature, dt, 1, 0.1)\n",
    "\n",
    "obs_intv = 8\n",
    "obs = nature + np.sqrt(2) * np.random.randn(*nature.shape)\n",
    "obs = obs[:,::obs_intv]\n",
    "\n",
    "R = np.eye(40) * 2\n",
    "\n",
    "X_ini = x0 + np.random.randint(-15, 15, size=x0.shape)\n",
    "N_ens = 30\n",
    "X_ens_ini = np.random.multivariate_normal(X_ini.ravel(), Pb, size=N_ens).T  # (ndim, N_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_oo(i, j, L=2):\n",
    "    if j < i:\n",
    "        i, j = j, i\n",
    "    dis_idx = j - i\n",
    "    if dis_idx > 20:\n",
    "        dis_idx = 40 - dis_idx\n",
    "    return np.exp(-dis_idx**2 / (2*L**2))\n",
    "\n",
    "def dis_mo(i, j, L=2):\n",
    "    return dis_oo(i, j, L)\n",
    "\n",
    "# localization for model to observation\n",
    "loc1 = np.zeros((40, 40))\n",
    "for i in range(40):\n",
    "    for j in range(40):\n",
    "        loc1[i,j] = dis_mo(i, j)\n",
    "        \n",
    "# localization for observation to observation\n",
    "loc2 = np.zeros((40, 40))\n",
    "for i in range(40):\n",
    "    for j in range(40):\n",
    "        loc2[i,j] = dis_oo(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.9450801334140161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ChunYehLu\\work\\SideProject\\Data-Assimilation\\model.py:87: RuntimeWarning: overflow encountered in multiply\n",
      "  x[:,idx+1] = xn + dt * ((xn_p1-xn_m2) * xn_m1 - xn + F)\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\numpy\\core\\_methods.py:75: RuntimeWarning: invalid value encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:174: RuntimeWarning: invalid value encountered in subtract\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:178: RuntimeWarning: invalid value encountered in subtract\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:179: RuntimeWarning: overflow encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:180: RuntimeWarning: overflow encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:180: RuntimeWarning: invalid value encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:192: RuntimeWarning: overflow encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:192: RuntimeWarning: invalid value encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "C:\\Users\\ChunYehLu\\AppData\\Local\\Continuum\\anaconda3\\envs\\as\\lib\\site-packages\\ipykernel_launcher.py:195: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnSRF, Mean RMSE:  nan\n",
      "ETKF, Mean RMSE:  1.1254783389162129\n",
      "EAKF, Mean RMSE:  0.9449260180624719\n"
     ]
    }
   ],
   "source": [
    "for Da in [EnKF, EnSRF, ETKF, EAKF]:\n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modified EnSRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original one\n",
    "\n",
    "class EnSRF2(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EnSRF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "           \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):\n",
    "        \"\"\"xb.shape = (n_dim, n_ens)\"\"\"\n",
    "        xb = xb.copy()\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (N_x, 1)\n",
    "        xb_pertb = xb - xb_mean   # (N_x, N_ens) \n",
    "        \n",
    "        for io, y in enumerate(yo):\n",
    "            # update mean field\n",
    "            Hxb_mean = H_func(xb)[io,:].mean()   # scalar\n",
    "            Hxb_pertb = H_func(xb)[io,:] - Hxb_mean   # (N_ens,)\n",
    "                \n",
    "            HPfH_T = np.cov(Hxb_pertb)   # scalar\n",
    "            PfH_T = np.empty((N_x, 1))\n",
    "            for ix in range(N_x):\n",
    "                PfH_T[ix] = np.cov(xb_pertb[ix,:], Hxb_pertb)[0,1]\n",
    "                \n",
    "            K = loc_mo[:,[io]] * PfH_T / (HPfH_T + R[io,io])   # (N_x, 1)\n",
    "            xa_mean = xb_mean + K * (y - H_func(xb)[io,:].mean())\n",
    "                \n",
    "            # update perturbation field\n",
    "            D = R[io,io] + HPfH_T\n",
    "            gamma = 1 / (1 + np.sqrt(R[io,io] / D))   # scalar\n",
    "            innovation_H = H_func(xb)[io,:] - H_func(xb)[io,:].mean()   # (N_ens,)\n",
    "            xa_pertb = xb_pertb - gamma * K * innovation_H   # (N_x, N_ens)\n",
    "            \n",
    "            # for next loop\n",
    "            xb_mean = xa_mean\n",
    "            xb_pertb = xa_pertb\n",
    "        \n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to pervious one but try to speed up\n",
    "\n",
    "def covariance(m1, v2, n):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between each row of `m1` and `v2`.\n",
    "    Parameters:\n",
    "        m1: numpy matrix with shape=(k, n)\n",
    "        v2: numpy array with shape=(n,)\n",
    "    Return:\n",
    "        covariance with shape=(k,) where i'th element is the covariance\n",
    "        between m1[i,:] and v2\n",
    "    \"\"\"\n",
    "    return ((m1 - m1.mean(axis=1)[:,np.newaxis]) * (v2 - v2.mean())).sum(axis=1) / (n-1)\n",
    "\n",
    "class EnSRF2(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EnSRF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "           \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):\n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        xb = xb.copy()\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (N_x, 1)\n",
    "        xb_pertb = xb - xb_mean   # (N_x, N_ens) \n",
    "        \n",
    "        Hxb = H_func(xb)   # (N_y, N_ens)\n",
    "        Hxb_mean = Hxb.mean(axis=1)[:,np.newaxis]   # (N_y, 1)\n",
    "        Hxb_pertb = Hxb - Hxb_mean   # (N_y, N_ens)\n",
    "        \n",
    "        for io, y in enumerate(yo):\n",
    "            # update mean field\n",
    "            iHxb_mean = Hxb_mean[io]   # scalar\n",
    "            iHxb_pertb = Hxb_pertb[io,:]   # (N_ens,)\n",
    "                \n",
    "            HPfH_T = np.cov(iHxb_pertb)   # scalar\n",
    "            PfH_T = covariance(xb_pertb, iHxb_pertb, N_ens)[:,np.newaxis]   # (N_x, 1)\n",
    "                \n",
    "            K = loc_mo[:,[io]] * PfH_T / (HPfH_T + R[io,io])   # (N_x, 1)\n",
    "            xa_mean = xb_mean + K * (y - iHxb_mean)\n",
    "                \n",
    "            # update perturbation field\n",
    "            D = R[io,io] + HPfH_T\n",
    "            gamma = 1 / (1 + np.sqrt(R[io,io] / D))   # scalar\n",
    "            innovation_H = Hxb[io,:] - iHxb_mean   # (N_ens,)\n",
    "            xa_pertb = xb_pertb - gamma * K * innovation_H   # (N_x, N_ens)\n",
    "            \n",
    "            # for next loop\n",
    "            xb_mean = xa_mean\n",
    "            xb_pertb = xa_pertb\n",
    "        \n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.9561451261750175\n",
      "2.703463077545166\n",
      "EnSRF2, Mean RMSE:  1.0097440720225648\n",
      "3.4122581481933594\n",
      "ETKF, Mean RMSE:  1.1254783389162129\n",
      "2.942962169647217\n",
      "EAKF, Mean RMSE:  0.9449260180624719\n",
      "18.19165349006653\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for Da in [EnKF, EnSRF2, ETKF, EAKF]:\n",
    "    time1 = time.time()\n",
    "    \n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the position of H_func and np.cov\n",
    "\n",
    "def covariance(m1, v2, n):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between each row of `m1` and `v2`.\n",
    "    Parameters:\n",
    "        m1: numpy matrix with shape=(k, n)\n",
    "        v2: numpy array with shape=(n,)\n",
    "    Return:\n",
    "        covariance with shape=(k,) where i'th element is the covariance\n",
    "        between m1[i,:] and v2\n",
    "    \"\"\"\n",
    "    return ((m1 - m1.mean(axis=1)[:,np.newaxis]) * (v2 - v2.mean())).sum(axis=1) / (n-1)\n",
    "\n",
    "class EnSRF2(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EnSRF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "           \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):\n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        xb = xb.copy()\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (N_x, 1)\n",
    "        xb_pertb = xb - xb_mean   # (N_x, N_ens) \n",
    "        \n",
    "        for io, y in enumerate(yo):\n",
    "            Hxb = H_func(xb)   # (N_y, N_ens)\n",
    "            Hxb_mean = Hxb.mean(axis=1)[:,np.newaxis]   # (N_y, 1)\n",
    "            Hxb_pertb = Hxb - Hxb_mean   # (N_y, N_ens)\n",
    "            iHxb_mean = Hxb_mean[io]   # scalar\n",
    "            iHxb_pertb = Hxb_pertb[io,:]   # (N_ens,)\n",
    "                    \n",
    "            # update mean field\n",
    "            HPfH_T = np.sum(iHxb_pertb**2) / (N_ens-1)   # scalar\n",
    "            PfH_T = covariance(xb_pertb, iHxb_pertb, N_ens)[:,np.newaxis]   # (N_x, 1)\n",
    "            K = loc_mo[:,[io]] * PfH_T / (HPfH_T + R[io,io])   # (N_x, 1)\n",
    "            xa_mean = xb_mean + K * (y - iHxb_mean)\n",
    "                \n",
    "            # update perturbation field\n",
    "            D = R[io,io] + HPfH_T\n",
    "            gamma = 1 / (1 + np.sqrt(R[io,io] / D))   # scalar\n",
    "            innovation_H = Hxb[io,:] - iHxb_mean   # (N_ens,)\n",
    "            xa_pertb = xb_pertb - gamma * K * innovation_H   # (N_x, N_ens)\n",
    "            \n",
    "            # for next loop\n",
    "            xb_mean = xa_mean\n",
    "            xb_pertb = xa_pertb\n",
    "            xb = xb_mean + xb_pertb\n",
    "        \n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.9506942170540202\n",
      "2.677966833114624\n",
      "EnSRF2, Mean RMSE:  0.9437663575378138\n",
      "3.061962604522705\n",
      "ETKF, Mean RMSE:  1.1254783389162129\n",
      "2.834963798522949\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for Da in [EnKF, EnSRF2, ETKF]:\n",
    "    time1 = time.time()\n",
    "    \n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change covariance\n",
    "\n",
    "def covariance(m1, v2, n):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between each row of `m1` and `v2`.\n",
    "    Parameters:\n",
    "        m1: numpy matrix with shape=(k, n)\n",
    "        v2: numpy array with shape=(n,)\n",
    "    Return:\n",
    "        covariance with shape=(k,) where i'th element is the covariance\n",
    "        between m1[i,:] and v2\n",
    "    \"\"\"\n",
    "    #return ((m1 - m1.mean(axis=1)[:,np.newaxis]) * (v2 - v2.mean())).sum(axis=1) / (n-1)\n",
    "    return np.dot(m1 - m1.mean(axis=1)[:,np.newaxis], v2 - v2.mean()) / (n-1)\n",
    "\n",
    "class EnSRF2(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EnSRF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "           \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):\n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        xb = xb.copy()\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (N_x, 1)\n",
    "        xb_pertb = xb - xb_mean   # (N_x, N_ens) \n",
    "        \n",
    "        for io, y in enumerate(yo):\n",
    "            Hxb = H_func(xb)   # (N_y, N_ens)\n",
    "            Hxb_mean = Hxb.mean(axis=1)[:,np.newaxis]   # (N_y, 1)\n",
    "            Hxb_pertb = Hxb - Hxb_mean   # (N_y, N_ens)\n",
    "            iHxb_mean = Hxb_mean[io]   # scalar\n",
    "            iHxb_pertb = Hxb_pertb[io,:]   # (N_ens,)\n",
    "                    \n",
    "            # update mean field\n",
    "            HPfH_T = np.sum(iHxb_pertb**2) / (N_ens-1)   # scalar\n",
    "            PfH_T = covariance(xb_pertb, iHxb_pertb, N_ens)[:,np.newaxis]   # (N_x, 1)\n",
    "            K = loc_mo[:,[io]] * PfH_T / (HPfH_T + R[io,io])   # (N_x, 1)\n",
    "            xa_mean = xb_mean + K * (y - iHxb_mean)\n",
    "                \n",
    "            # update perturbation field\n",
    "            D = R[io,io] + HPfH_T\n",
    "            gamma = 1 / (1 + np.sqrt(R[io,io] / D))   # scalar\n",
    "            innovation_H = Hxb[io,:] - iHxb_mean   # (N_ens,)\n",
    "            xa_pertb = xb_pertb - gamma * K * innovation_H   # (N_x, N_ens)\n",
    "            \n",
    "            # for next loop\n",
    "            xb_mean = xa_mean\n",
    "            xb_pertb = xa_pertb\n",
    "            xb = xb_mean + xb_pertb\n",
    "        \n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.9428712362712797\n",
      "2.7121872901916504\n",
      "EnSRF2, Mean RMSE:  0.9437663575378128\n",
      "3.092928886413574\n",
      "ETKF, Mean RMSE:  1.1254783389162129\n",
      "3.453951120376587\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for Da in [EnKF, EnSRF2, ETKF]:\n",
    "    time1 = time.time()\n",
    "    \n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modified EAKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EAKF2(EnsembleBase): \n",
    "    \"\"\"\n",
    "    Ensemble Adjustment Kalman Filter\n",
    "    \n",
    "    It based on the 2-step procedure of Anderson (2003), and followed the \n",
    "    step-by-step introduction of Shen et al. (2018) or Liu el al. (2007).\n",
    "    \n",
    "    *Reference\n",
    "    [1]\n",
    "    Zheqi Shen, Youmin Tang, Xiaojing Li, Yanqiu Gao, and Junde Li, 2018:\n",
    "    On the localization in strongly coupled ensemble data assimilationusing \n",
    "    a two-scale Lorenz model\n",
    "    https://www.nonlin-processes-geophys-discuss.net/npg-2018-50/\n",
    "    \n",
    "    [2]\n",
    "    Anderson, 2003: A local least squares framework for ensemble filtering\n",
    "    https://doi.org/10.1175/1520-0493(2003)131<0634:ALLSFF>2.0.CO;2\n",
    "    \n",
    "    [3]\n",
    "    Liu, H., J. Anderson, Y.-H. Kuo, and K. Raeder, 2007: Importance of \n",
    "    forecast error multivariate correlations in idealized assimilation of GPS\n",
    "    radio occultation data with the ensemble adjustment filter. \n",
    "    https://journals.ametsoc.org/doi/abs/10.1175/MWR3270.1\n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            self._params['local'] = (loc_mo,)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "        \n",
    "        # check if R is diagonal matrix\n",
    "        R = self._params['R']\n",
    "        Rnew = np.zeros_like(R)\n",
    "        np.fill_diagonal(Rnew, R.diagonal())\n",
    "        if not np.all(R == Rnew):\n",
    "            messg = 'EAKF assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "    \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):  \n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        # serially assimilation\n",
    "        xa = xb.copy()\n",
    "        for io, iyo in enumerate(yo):\n",
    "            ### step 1\n",
    "            # estimate background field at the observation space\n",
    "            #yp = np.empty(N_ens)\n",
    "            #for iens in range(N_ens):\n",
    "            #    yp[iens] = H_func(xa[:,[iens]])[io]\n",
    "            yp = H_func(xa)[io,:]   # (N_ens,)\n",
    "                \n",
    "            # analysis for the background field at the observation space\n",
    "            yp_mean = yp.mean()\n",
    "            #yp_var = yp.var()\n",
    "            yp_var = np.sum((yp - yp_mean)**2) / (N_ens-1)\n",
    "            r = R[io,io]\n",
    "            yu_var = 1 / (1/yp_var + 1/r)\n",
    "            yu_mean = yu_var * (yp_mean / yp_var + iyo / r)\n",
    "            yu = np.sqrt(yu_var / yp_var) * (yp - yp_mean) + yu_mean   # (N_ens,)\n",
    "            increment_y = yu - yp   # (N_ens,)\n",
    "            \n",
    "            ### step 2 \n",
    "            #cov_xy_states = covariance(xa, yp, N_ens)   # (N_x,)\n",
    "            #for jstate in range(N_x):\n",
    "            #    cov_xy = cov_xy_states[jstate]\n",
    "            #    increment_x = cov_xy / yp_var * increment_y   # (N_ens,)\n",
    "            #    xa[jstate,:] += loc_mo[jstate,io] * increment_x\n",
    "            cov_xy_states = covariance(xa, yp, N_ens)   # (N_x,)\n",
    "            increment_x_states = cov_xy_states[:,np.newaxis] / yp_var * increment_y   # (N_x, N_ens)\n",
    "            xa += loc_mo[:,[io]] * increment_x_states\n",
    "                \n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAKF2, Mean RMSE:  0.9437663575378132\n",
      "3.1144251823425293\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for Da in [EAKF2]:\n",
    "    time1 = time.time()\n",
    "    \n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():        \n",
    "    da = EAKF2(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1,)\n",
    "    }\n",
    "    da.set_params(**params)\n",
    "    da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAKF2, Mean RMSE:  0.9437663575378132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 2.68282e-07 s\n",
       "\n",
       "Total time: 0.951675 s\n",
       "File: <ipython-input-62-fc0aa67c53dc>\n",
       "Function: _analysis at line 44\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    44                                               def _analysis(self, xb, yo, R, H_func, loc_mo):  \n",
       "    45                                                   \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
       "    46       125       1223.0      9.8      0.0          N_x, N_ens = xb.shape\n",
       "    47                                                   \n",
       "    48                                                   # serially assimilation\n",
       "    49       125       2577.0     20.6      0.1          xa = xb.copy()\n",
       "    50      5125      37841.0      7.4      1.1          for io, iyo in enumerate(yo):\n",
       "    51                                                       ### step 1\n",
       "    52                                                       # estimate background field at the observation space\n",
       "    53                                                       #yp = np.empty(N_ens)\n",
       "    54                                                       #for iens in range(N_ens):\n",
       "    55                                                       #    yp[iens] = H_func(xa[:,[iens]])[io]\n",
       "    56      5000      50527.0     10.1      1.4              yp = H_func(xa)[io,:]   # (N_ens,)\n",
       "    57                                                           \n",
       "    58                                                       # analysis for the background field at the observation space\n",
       "    59      5000     463009.0     92.6     13.1              yp_mean = yp.mean()\n",
       "    60                                                       #yp_var = yp.var()\n",
       "    61      5000     417065.0     83.4     11.8              yp_var = np.sum((yp - yp_mean)**2) / (N_ens-1)\n",
       "    62      5000      34339.0      6.9      1.0              r = R[io,io]\n",
       "    63      5000      51252.0     10.3      1.4              yu_var = 1 / (1/yp_var + 1/r)\n",
       "    64      5000     200420.0     40.1      5.6              yu_mean = yu_var * (yp_mean / yp_var + iyo / r)\n",
       "    65      5000     252800.0     50.6      7.1              yu = np.sqrt(yu_var / yp_var) * (yp - yp_mean) + yu_mean   # (N_ens,)\n",
       "    66      5000      49177.0      9.8      1.4              increment_y = yu - yp   # (N_ens,)\n",
       "    67                                                       \n",
       "    68                                                       ### step 2 \n",
       "    69                                                       #cov_xy_states = covariance(xa, yp, N_ens)   # (N_x,)\n",
       "    70                                                       #for jstate in range(N_x):\n",
       "    71                                                       #    cov_xy = cov_xy_states[jstate]\n",
       "    72                                                       #    increment_x = cov_xy / yp_var * increment_y   # (N_ens,)\n",
       "    73                                                       #    xa[jstate,:] += loc_mo[jstate,io] * increment_x\n",
       "    74      5000    1333576.0    266.7     37.6              cov_xy_states = covariance(xa, yp, N_ens)   # (N_x,)\n",
       "    75      5000     244563.0     48.9      6.9              increment_x_states = cov_xy_states[:,np.newaxis] / yp_var * increment_y   # (N_x, N_ens)\n",
       "    76      5000     408459.0     81.7     11.5              xa += loc_mo[:,[io]] * increment_x_states\n",
       "    77                                                           \n",
       "    78       125        467.0      3.7      0.0          return xa"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f da._analysis test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modified ETKF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETKF2(EnsembleBase):\n",
    "    \"\"\"\n",
    "    Ensemble Transform Kalman Filter\n",
    "    \n",
    "    It should note that localization is only used for updating ensemble mean \n",
    "    of K method (e.g etkf.cycle(mean_method='K')). There is no localization\n",
    "    for w method (e.g etkf.cycle(mean_method='w')).\n",
    "    \n",
    "    And localization is for ensemble mean only, there is no localization for \n",
    "    updating ensemble perturbation.\n",
    "    \n",
    "    *Reference\n",
    "    Update ensemble mean of w method:\n",
    "        Harlim and Hunt: Local Ensemble Transform Kalman Filter: An efficient\n",
    "        scheme for assimilating atmospheric data.\n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "    Update ensemble perturbation:\n",
    "        Tippett, M. K., J. L. Anderson, C. H. Bishop, T. M. Hamill, and J. S. \n",
    "        Whitaker, 2003: Ensemble square root filters.\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2      \n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "            ndim_obs = self._params.get('obs').shape[0]\n",
    "            loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "            loc_oo = np.ones((ndim_obs, ndim_obs))\n",
    "            self._params['local'] = (loc_mo, loc_oo)            \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "    \n",
    "    def _analysis_mean_w(self, xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R):\n",
    "        \"\"\"\n",
    "        Using the w vector in Harlim and Hunt* to update background ensemble\n",
    "        mean to analysis mean.\n",
    "        *Reference: \n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "        \"\"\"\n",
    "        P_tilt = np.linalg.inv(Hxb_pertb.T @ np.linalg.inv(R) @ Hxb_pertb + (N_ens-1) * np.eye(N_ens))\n",
    "        w = P_tilt @ Hxb_pertb.T @ np.linalg.inv(R) @ (yo - Hxb_mean)\n",
    "        xa_mean = xb_mean + xb_pertb @ w\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_mean_K(self, xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo):\n",
    "        \"\"\"\n",
    "        Using the K matrix (Kalman gain matrix) in traditional Kalman filter to\n",
    "        upate background ensemble mean to analysis ensemble mean.\n",
    "        \"\"\"\n",
    "        PfH_T = xb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        HPfH_T = Hxb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(loc_oo * HPfH_T + R)\n",
    "        xa_mean = xb_mean + K @ (yo - H_func(xb_mean))\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_perturb(self, xb_pertb, Hxb_pertb, N_ens, R):\n",
    "        \"\"\"\n",
    "        Update background ensemble perturbation tp analysis ensemble perturbation.\n",
    "        *Reference:\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2\n",
    "        \"\"\"\n",
    "        Z = xb_pertb / np.sqrt(N_ens-1)\n",
    "        HZ = Hxb_pertb / np.sqrt(N_ens-1)\n",
    "        eigval, C = np.linalg.eig(HZ.T @ np.linalg.inv(R) @ HZ)\n",
    "        T = C @ np.diag(1 / np.sqrt(1 + eigval))\n",
    "        T = T.real   # imag part is likely due to numerical error\n",
    "        xa_pertb = xb_pertb @ T\n",
    "        return xa_pertb\n",
    "        \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo, loc_oo, mean_method='w'):       \n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        xb_pertb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        Hxb_pertb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        \n",
    "        if mean_method == 'w':\n",
    "            xa_mean = self._analysis_mean_w(xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R)\n",
    "        elif mean_method == 'K':\n",
    "            xa_mean = self._analysis_mean_K(xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo)\n",
    "        else:\n",
    "            raise TypeError('`mean_method` should be \"w\" or \"K\"')\n",
    "            \n",
    "        xa_pertb = self._analysis_perturb(xb_pertb, Hxb_pertb, N_ens, R)\n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa\n",
    "    \n",
    "    def cycle(self, mean_method='w'):\n",
    "        super().cycle(mean_method=mean_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETKF2, Mean RMSE:  1.1513501733208094\n",
      "2.910527467727661\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time1 = time.time()\n",
    "da = ETKF2(lorenz96_fdm, dt)\n",
    "params = {\n",
    "    'X_ens_ini': X_ens_ini,\n",
    "    'obs': obs,\n",
    "    'obs_interv': obs_intv,\n",
    "    'R': R,\n",
    "    'H_func': lambda arr: arr,\n",
    "    'alpha': 0.4,\n",
    "    'inflat': 1.5,\n",
    "    'local': (loc1, loc2)\n",
    "}\n",
    "da.set_params(**params)\n",
    "da.cycle(mean_method='K')\n",
    "\n",
    "analysis = da.analysis.mean(axis=0)\n",
    "name = da.__str__().split('.')[1].split()[0]\n",
    "print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())\n",
    "time2 = time.time()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _covariance(m1, v2, n):\n",
    "    \"\"\"\n",
    "    Calculate the covariance between each row of `m1` and `v2`.\n",
    "    Parameters:\n",
    "        m1: numpy matrix with shape=(k, n)\n",
    "        v2: numpy array with shape=(n,)\n",
    "    Return:\n",
    "        covariance with shape=(k,) where i'th element is the covariance\n",
    "        between m1[i,:] and v2\n",
    "    \"\"\"\n",
    "    #return ((m1 - m1.mean(axis=1)[:,np.newaxis]) * (v2 - v2.mean())).sum(axis=1) / (n-1)\n",
    "    return np.dot(m1 - m1.mean(axis=1)[:,np.newaxis], v2 - v2.mean()) / (n-1)\n",
    "\n",
    "def _isdiag(matrix):\n",
    "    \"\"\"Check if `matrix` is a diagonal matrix. Used in serial assimilation.\"\"\"\n",
    "    i, j = matrix.shape\n",
    "    assert i == j \n",
    "    test = matrix.reshape(-1)[:-1].reshape(i-1,j+1)\n",
    "    return ~np.any(test[:,1:])\n",
    "\n",
    "\n",
    "class DiagWarning(UserWarning):\n",
    "    \"\"\"Used in serially assimilation when R is not diagonal\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DAbase:\n",
    "    def __init__(self, model, dt, store_history=False):\n",
    "        self._isstore = store_history\n",
    "        self._params = {'alpha': 0, 'inflat': 1}\n",
    "        self.model = model\n",
    "        self.dt = dt\n",
    "        self.X_ini = None\n",
    "        \n",
    "    def set_params(self, param_list, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if key in param_list:\n",
    "                self._params[key] = kwargs.get(key)\n",
    "            else:\n",
    "                raise ValueError(f'Invalid parameter: {key}')\n",
    "        \n",
    "    def _check_params(self, param_list):\n",
    "        missing_params = []\n",
    "        for var in param_list:\n",
    "            if self._params.get(var) is None:\n",
    "                missing_params.append(var)\n",
    "        return missing_params\n",
    "    \n",
    "    \n",
    "class EnsembleBase(DAbase):    \n",
    "    def __init__(self, model, dt, store_history=False):\n",
    "        super().__init__(model, dt, store_history)\n",
    "        self._param_list = [\n",
    "            'X_ens_ini', \n",
    "            'obs', \n",
    "            'obs_interv', \n",
    "            'R', \n",
    "            'H_func', \n",
    "            'alpha', \n",
    "            'inflat',\n",
    "            'local',\n",
    "        ]\n",
    "    \n",
    "    def list_params(self):\n",
    "        return self._param_list\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        local = kwargs.get('local')\n",
    "        if local is not None and not isinstance(local, (tuple, list)):\n",
    "            kwargs['local'] = tuple(local)\n",
    "        super().set_params(self._param_list, **kwargs)\n",
    "    \n",
    "    def _check_params(self):\n",
    "        if self._params.get('H_func') is None:\n",
    "            H_func = lambda arr: arr\n",
    "            self._params['H_func']\n",
    "        \n",
    "        missing_params = super()._check_params(self._param_list)\n",
    "        if missing_params:\n",
    "            raise ValueError(f\"Missing parameters: {missing_params}\")\n",
    "            \n",
    "    def _check_R_diag(self):\n",
    "        if not _isdiag(self._params['R']):\n",
    "            name = self.__class__.__name__\n",
    "            messg = f'{name} assimilates observations serially. It suggests that R should be diagonal matrix.'\n",
    "            warnings.warn(messg, DiagWarning)\n",
    "            \n",
    "    def _default_local(self, is_loc_mo=False, is_loc_oo=False):\n",
    "        ndim_model = self._params.get('X_ens_ini').shape[0]\n",
    "        ndim_obs = self._params.get('obs').shape[0]\n",
    "        loc_mo = np.ones((ndim_model, ndim_obs))\n",
    "        loc_oo = np.ones((ndim_obs, ndim_obs))\n",
    "        \n",
    "        if is_loc_mo and is_loc_oo:\n",
    "            return loc_mo, loc_oo\n",
    "        elif is_loc_mo and not is_loc_oo:\n",
    "            return loc_mo\n",
    "        elif not is_loc_mo and is_loc_oo:\n",
    "            return loc_oo\n",
    "            \n",
    "    def _analysis(self):\n",
    "        pass\n",
    "            \n",
    "    def cycle(self, **kwargs):\n",
    "        self._check_params()\n",
    "        \n",
    "        model = self.model\n",
    "        dt = self.dt\n",
    "        cycle_len = self._params['obs_interv']\n",
    "        cycle_num = self._params['obs'].shape[1]\n",
    "        \n",
    "        xb = self._params['X_ens_ini'].copy()\n",
    "        obs = self._params['obs']\n",
    "        R = self._params['R']\n",
    "        H_func = self._params['H_func']\n",
    "        alpha = self._params['alpha']\n",
    "        inflat = self._params['inflat']\n",
    "        local = self._params['local']\n",
    "        \n",
    "        ndim, N_ens = xb.shape\n",
    "        background = np.zeros((N_ens, ndim, cycle_len*cycle_num))\n",
    "        analysis = np.zeros_like(background)\n",
    "        \n",
    "        t_start = 0\n",
    "        ts = np.linspace(t_start, (cycle_len-1)*dt, cycle_len)\n",
    "        \n",
    "        for nc in range(cycle_num):\n",
    "            # analysis\n",
    "            xa = self._analysis(xb, obs[:,[nc]], R, H_func, *local, **kwargs)\n",
    "            \n",
    "            # inflat\n",
    "            xa_perturb = xa - xa.mean(axis=1)[:,np.newaxis]\n",
    "            xa_perturb *= inflat\n",
    "            xa = xa.mean(axis=1)[:,np.newaxis] + xa_perturb\n",
    "            \n",
    "            # ensemble forecast\n",
    "            for iens in range(N_ens):\n",
    "                x_forecast = model(xa[:,iens], ts)   # (ndim, ts.size)\n",
    "                \n",
    "                idx1 = nc*cycle_len\n",
    "                idx2 = (nc+1)*cycle_len\n",
    "                analysis[iens,:,idx1:idx2] = x_forecast\n",
    "                background[iens,:,[idx1]] = xb[:,iens]\n",
    "                background[iens,:,(idx1+1):idx2] = x_forecast[:,1:]\n",
    "                \n",
    "                # xb for next cycle\n",
    "                xb[:,iens] = x_forecast[:,-1]\n",
    "                \n",
    "            # for next cycle\n",
    "            t_start = int(ts[-1] + dt)\n",
    "            ts = np.linspace(t_start, t_start+(cycle_len-1)*dt, cycle_len)\n",
    "            \n",
    "        self.background = background\n",
    "        self.analysis = analysis\n",
    "\n",
    "\n",
    "class EnKF(EnsembleBase):\n",
    "    def _check_params(self):          \n",
    "        if self._params.get('local') is None:\n",
    "            loc_mo, loc_oo = self._default_local(is_loc_mo=True, is_loc_oo=True)\n",
    "            self._params['local'] = (loc_mo, loc_oo)\n",
    "        super()._check_params()\n",
    " \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo, loc_oo, random_state=None):\n",
    "        \"\"\"xb.shape = (n_dim, n_ens)\"\"\"\n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        Xb_perturb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        HXb_perturb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        \n",
    "        PfH_T = Xb_perturb @ HXb_perturb.T / (N_ens-1)\n",
    "        HPfH_T = HXb_perturb @ HXb_perturb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(loc_oo * HPfH_T + R)\n",
    "        \n",
    "        rst = np.random.RandomState(seed=random_state)\n",
    "        yo_ens = rst.multivariate_normal(yo.ravel(), R, size=N_ens).T   # (ndim_yo, N_ens)\n",
    "        xa_ens = np.zeros((xb.shape[0], N_ens))\n",
    "        for iens in range(N_ens):            \n",
    "            xa_ens[:,[iens]] = xb[:,[iens]] + K @ (yo_ens[:,[iens]] - H_func(xb[:,[iens]]))\n",
    "            \n",
    "        return xa_ens\n",
    "    \n",
    "    def cycle(self, random_state=None):\n",
    "        super().cycle(random_state=random_state)\n",
    "\n",
    "\n",
    "class EnSRF(EnsembleBase):         \n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            loc_mo = self._default_local(is_loc_mo=True)\n",
    "            self._params['local'] = (loc_mo,)\n",
    "        \n",
    "        # check parameters and check if R is diagonal matrix\n",
    "        super()._check_params()\n",
    "        self._check_R_diag()\n",
    "           \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):\n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        xb = xb.copy()\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (N_x, 1)\n",
    "        xb_pertb = xb - xb_mean   # (N_x, N_ens) \n",
    "        \n",
    "        for io, y in enumerate(yo):\n",
    "            Hxb = H_func(xb)   # (N_y, N_ens)\n",
    "            Hxb_mean = Hxb.mean(axis=1)[:,np.newaxis]   # (N_y, 1)\n",
    "            Hxb_pertb = Hxb - Hxb_mean   # (N_y, N_ens)\n",
    "            iHxb_mean = Hxb_mean[io]   # scalar\n",
    "            iHxb_pertb = Hxb_pertb[io,:]   # (N_ens,)\n",
    "                    \n",
    "            # update mean field\n",
    "            HPfH_T = np.sum(iHxb_pertb**2) / (N_ens-1)   # scalar\n",
    "            PfH_T = _covariance(xb_pertb, iHxb_pertb, N_ens)[:,np.newaxis]   # (N_x, 1)\n",
    "            K = loc_mo[:,[io]] * PfH_T / (HPfH_T + R[io,io])   # (N_x, 1)\n",
    "            xa_mean = xb_mean + K * (y - iHxb_mean)\n",
    "                \n",
    "            # update perturbation field\n",
    "            D = R[io,io] + HPfH_T\n",
    "            gamma = 1 / (1 + np.sqrt(R[io,io] / D))   # scalar\n",
    "            innovation_H = Hxb[io,:] - iHxb_mean   # (N_ens,)\n",
    "            xa_pertb = xb_pertb - gamma * K * innovation_H   # (N_x, N_ens)\n",
    "            \n",
    "            # for next loop\n",
    "            xb_mean = xa_mean\n",
    "            xb_pertb = xa_pertb\n",
    "            xb = xb_mean + xb_pertb\n",
    "        \n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa\n",
    "    \n",
    "    \n",
    "class ETKF(EnsembleBase):\n",
    "    \"\"\"\n",
    "    Ensemble Transform Kalman Filter\n",
    "    \n",
    "    It should note that localization is only used for updating ensemble mean \n",
    "    of K method (e.g etkf.cycle(mean_method='K')). There is no localization\n",
    "    for w method (e.g etkf.cycle(mean_method='w')).\n",
    "    \n",
    "    And localization is for ensemble mean only, there is no localization for \n",
    "    updating ensemble perturbation.\n",
    "    \n",
    "    *Reference\n",
    "    Update ensemble mean of w method:\n",
    "        Harlim and Hunt: Local Ensemble Transform Kalman Filter: An efficient\n",
    "        scheme for assimilating atmospheric data.\n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "    Update ensemble perturbation:\n",
    "        Tippett, M. K., J. L. Anderson, C. H. Bishop, T. M. Hamill, and J. S. \n",
    "        Whitaker, 2003: Ensemble square root filters.\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2      \n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            loc_mo, loc_oo = self._default_local(is_loc_mo=True, is_loc_oo=True)\n",
    "            self._params['local'] = (loc_mo, loc_oo)         \n",
    "        \n",
    "        # check parameters\n",
    "        super()._check_params()\n",
    "    \n",
    "    def _analysis_mean_w(self, xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R):\n",
    "        \"\"\"\n",
    "        Using the w vector in Harlim and Hunt* to update background ensemble\n",
    "        mean to analysis mean.\n",
    "        *Reference: \n",
    "        https://www.atmos.umd.edu/~ekalnay/pubs/harlim_hunt05.pdf\n",
    "        \"\"\"\n",
    "        P_tilt = np.linalg.inv(Hxb_pertb.T @ np.linalg.inv(R) @ Hxb_pertb + (N_ens-1) * np.eye(N_ens))\n",
    "        w = P_tilt @ Hxb_pertb.T @ np.linalg.inv(R) @ (yo - Hxb_mean)\n",
    "        xa_mean = xb_mean + xb_pertb @ w\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_mean_K(self, xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo):\n",
    "        \"\"\"\n",
    "        Using the K matrix (Kalman gain matrix) in traditional Kalman filter to\n",
    "        upate background ensemble mean to analysis ensemble mean.\n",
    "        \"\"\"\n",
    "        PfH_T = xb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        HPfH_T = Hxb_pertb @ Hxb_pertb.T / (N_ens-1)\n",
    "        K = loc_mo * PfH_T @ np.linalg.inv(loc_oo * HPfH_T + R)\n",
    "        xa_mean = xb_mean + K @ (yo - H_func(xb_mean))\n",
    "        return xa_mean\n",
    "    \n",
    "    def _analysis_perturb(self, xb_pertb, Hxb_pertb, N_ens, R):\n",
    "        \"\"\"\n",
    "        Update background ensemble perturbation tp analysis ensemble perturbation.\n",
    "        *Reference:\n",
    "        https://journals.ametsoc.org/doi/pdf/10.1175/1520-0493%282003%29131%3C1485%3AESRF%3E2.0.CO%3B2\n",
    "        \"\"\"\n",
    "        Z = xb_pertb / np.sqrt(N_ens-1)\n",
    "        HZ = Hxb_pertb / np.sqrt(N_ens-1)\n",
    "        eigval, C = np.linalg.eig(HZ.T @ np.linalg.inv(R) @ HZ)\n",
    "        T = C @ np.diag(1 / np.sqrt(1 + eigval))\n",
    "        T = T.real   # imag part is likely due to numerical error\n",
    "        xa_pertb = xb_pertb @ T\n",
    "        return xa_pertb\n",
    "        \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo, loc_oo, mean_method='w'):       \n",
    "        N_ens = xb.shape[1]\n",
    "        xb_mean = xb.mean(axis=1)[:,np.newaxis]   # (ndim_xb, 1)\n",
    "        xb_pertb = xb - xb_mean   # (ndim_xb, N_ens)\n",
    "        Hxb_mean = H_func(xb).mean(axis=1)[:,np.newaxis]   # (ndim_yo, 1)\n",
    "        Hxb_pertb = H_func(xb) - Hxb_mean   # (ndim_yo, N_ens)\n",
    "        \n",
    "        if mean_method == 'w':\n",
    "            xa_mean = self._analysis_mean_w(xb_mean, xb_pertb, Hxb_mean, Hxb_pertb, N_ens, yo, R)\n",
    "        elif mean_method == 'K':\n",
    "            xa_mean = self._analysis_mean_K(xb_mean, xb_pertb, Hxb_pertb, N_ens, yo, R, H_func, loc_mo, loc_oo)\n",
    "        else:\n",
    "            raise TypeError('`mean_method` should be \"w\" or \"K\"')\n",
    "            \n",
    "        xa_pertb = self._analysis_perturb(xb_pertb, Hxb_pertb, N_ens, R)\n",
    "        xa = xa_mean + xa_pertb\n",
    "        return xa\n",
    "    \n",
    "    def cycle(self, mean_method='w'):\n",
    "        super().cycle(mean_method=mean_method)\n",
    "        \n",
    "        \n",
    "class EAKF(EnsembleBase): \n",
    "    \"\"\"\n",
    "    Ensemble Adjustment Kalman Filter\n",
    "    \n",
    "    It based on the 2-step procedure of Anderson (2003), and followed the \n",
    "    step-by-step introduction of Shen et al. (2018) or Liu el al. (2007).\n",
    "    \n",
    "    *Reference\n",
    "    [1]\n",
    "    Zheqi Shen, Youmin Tang, Xiaojing Li, Yanqiu Gao, and Junde Li, 2018:\n",
    "    On the localization in strongly coupled ensemble data assimilationusing \n",
    "    a two-scale Lorenz model\n",
    "    https://www.nonlin-processes-geophys-discuss.net/npg-2018-50/\n",
    "    \n",
    "    [2]\n",
    "    Anderson, 2003: A local least squares framework for ensemble filtering\n",
    "    https://doi.org/10.1175/1520-0493(2003)131<0634:ALLSFF>2.0.CO;2\n",
    "    \n",
    "    [3]\n",
    "    Liu, H., J. Anderson, Y.-H. Kuo, and K. Raeder, 2007: Importance of \n",
    "    forecast error multivariate correlations in idealized assimilation of GPS\n",
    "    radio occultation data with the ensemble adjustment filter. \n",
    "    https://journals.ametsoc.org/doi/abs/10.1175/MWR3270.1\n",
    "    \"\"\"\n",
    "    def _check_params(self):\n",
    "        # default setting\n",
    "        if self._params.get('local') is None:\n",
    "            loc_mo = self._default_local(is_loc_mo=True)\n",
    "            self._params['local'] = (loc_mo,)          \n",
    "        \n",
    "        # check parameters and check if R is diagonal matrix\n",
    "        super()._check_params()\n",
    "        self._check_R_diag()\n",
    "    \n",
    "    def _analysis(self, xb, yo, R, H_func, loc_mo):  \n",
    "        \"\"\"xb.shape = (N_x, N_ens)\"\"\"\n",
    "        N_x, N_ens = xb.shape\n",
    "        \n",
    "        # serially assimilation\n",
    "        xa = xb.copy()\n",
    "        for io, iyo in enumerate(yo):\n",
    "            ### step 1\n",
    "            # estimate background field at the observation space\n",
    "            yp = H_func(xa)[io,:]   # (N_ens,)\n",
    "                \n",
    "            # analysis for the background field at the observation space\n",
    "            yp_mean = yp.mean()\n",
    "            yp_var = np.sum((yp - yp_mean)**2) / (N_ens-1)\n",
    "            r = R[io,io]\n",
    "            yu_var = 1 / (1/yp_var + 1/r)\n",
    "            yu_mean = yu_var * (yp_mean / yp_var + iyo / r)\n",
    "            yu = np.sqrt(yu_var / yp_var) * (yp - yp_mean) + yu_mean   # (N_ens,)\n",
    "            increment_y = yu - yp   # (N_ens,)\n",
    "            \n",
    "            ### step 2 \n",
    "            cov_xy_states = _covariance(xa, yp, N_ens)   # (N_x,)\n",
    "            increment_x_states = cov_xy_states[:,np.newaxis] / yp_var * increment_y   # (N_x, N_ens)\n",
    "            xa += loc_mo[:,[io]] * increment_x_states\n",
    "                \n",
    "        return xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnKF, Mean RMSE:  0.9300048445638943\n",
      "EnSRF, Mean RMSE:  0.9266270182116392\n",
      "ETKF, Mean RMSE:  1.102719872230467\n",
      "EAKF, Mean RMSE:  0.9266270182116393\n"
     ]
    }
   ],
   "source": [
    "for Da in [EnKF, EnSRF, ETKF, EAKF]:\n",
    "    da = Da(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "    }\n",
    "    if Da in [EnKF, ETKF]:\n",
    "        params['local'] = (loc1, loc2)\n",
    "    else:\n",
    "        params['local'] = (loc1,)\n",
    "    da.set_params(**params)\n",
    "    \n",
    "    if Da is ETKF:\n",
    "        da.cycle(mean_method='K')\n",
    "    elif Da is EnKF:\n",
    "        da.cycle()\n",
    "    else:\n",
    "        da.cycle()\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    \n",
    "    name = da.__str__().split('.')[1].split()[0]\n",
    "    print(name + ', Mean RMSE: ', da_rmse(nature, analysis, obs_intv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1127781706911606\n",
      "1 1.1138001155678579\n",
      "2 1.1206119752916517\n",
      "3 1.1291263315300275\n",
      "4 1.1116639054646738\n",
      "5 1.106930572901526\n",
      "6 1.1044092336795808\n",
      "7 1.111391046434195\n",
      "8 1.1261910641683837\n",
      "9 1.1204035986623504\n",
      "10 1.1036391830926335\n",
      "11 1.109070014051735\n",
      "12 1.1162063540256706\n",
      "13 1.118571829946433\n",
      "14 1.13563489437062\n",
      "15 1.1173907891599326\n",
      "16 1.1021783784254295\n",
      "17 1.1265696100427387\n",
      "18 1.1359512872950592\n",
      "19 1.1163339959102339\n",
      "20 1.1215044842242528\n",
      "21 1.1178066296798521\n",
      "22 1.1311339905649345\n",
      "23 1.1245671805787556\n",
      "24 1.124292506724144\n"
     ]
    }
   ],
   "source": [
    "for seed in range(25):\n",
    "    da = EnKF(lorenz96_fdm, dt)\n",
    "    params = {\n",
    "        'X_ens_ini': X_ens_ini,\n",
    "        'obs': obs,\n",
    "        'obs_interv': obs_intv,\n",
    "        'R': R,\n",
    "        'H_func': lambda arr: arr,\n",
    "        'alpha': 0.4,\n",
    "        'inflat': 1.5,\n",
    "        'local': (loc1, loc2)\n",
    "    }\n",
    "    da.set_params(**params)\n",
    "    da.cycle(random_state=seed)\n",
    "    analysis = da.analysis.mean(axis=0)\n",
    "    print(seed, da_rmse(nature, analysis, obs_intv).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
